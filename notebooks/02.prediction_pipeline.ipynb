{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d6484f44-412d-4568-a5ae-9ee9cd1e73b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import string\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5adfba97-0d9a-495d-9365-890865b77fb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_punctuations(text):\n",
    "    for punctuation in string.punctuation:\n",
    "        text = text.replace(punctuation, '')\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "77a8ea50-45be-421c-9a84-83eaa8d92bd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../static/model/modelmnb.pickle', 'rb') as f:\n",
    "    model = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "17b7a7a4-637b-49c8-8694-1ce568792251",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../static/model/corpora/stopwords/english', 'r') as file:\n",
    "    sw = file.read().splitlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7042f350-4659-41f7-a481-6a1494e836a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['materi', 'eka', 'perfect', 'ithin', 'satisfi', 'phone', 'super', 'shiok', 'damn', 'order', 'deliveri', 'fast', 'seller', 'respons', 'sia.', 'repli', 'size', 'cannot', 'qualiti', 'money', 'slow', 'one', 'week', 'custom', 'servic', 'chat', 'ekanam', 'hondai,', 'meka', 'mara', 'lassanai,', 'welawatama', 'una,', 'meke', 'build', 'supiri', 'ekak,', 'time', 'hariyata', 'dunna', 'eke', 'use', 'karanawa,', 'godak', 'practic', 'wenawa.', 'supiri,', 'warranti', 'watinawa.', 'menu', 'athi', 'product', 'maru', 'hithapu', 'nadda', 'ekak', 'karanna', 'sound', 'idin', 'issu', 'kalin', 'care', 'ekata', 'balaporoththu', 'eka.', 'lassanai', 'hondai', 'puluwan', 'price', 'hari', 'hodai', 'wenawa', 'set', 'hariyatama', 'thiyenawa', 'una', 'disappoint', 'ne', 'aduwata', 'aya', 'amarui', 'thibuna', 'karaddi', 'hodata', 'ganna', 'hithuwatath', 'wada', 'ikmanata', 'awa', 'hondata', 'weda', 'karanawa', 'wedak', 'na', 'pata', 'harima', 'oder', 'karapu', 'newei', 'wena', 'wela', 'ekedi', 'damag', 'kedila', 'kethai', 'hithuwata', 'ewa', 'nam', 'epa', 'podi', 'lokui', 'unata', 'brand', 'dawa', 'keduna', 'mekata', 'enn', 'mekanam', 'mewa', 'badu', 'ganata', 'watinawa', 'padu', 'gewapu', 'kotuwata', 'labai', 'marama', 'wire', 'color', 'awe', 'tharam', 'haiya', 'mic', 'hodatama', 'okkoma', 'samahara', 'damg', 'baduwak', 'wage', 'habai', 'naa', 'wadiya', 'sauththui', 'melo', 'apo', 'madi', 'add', 'thiyana', 'photo', 'ewann', 'boru', 'descript', 'dala', 'minissu', 'meyala', 'karann', 'tiyena', 'new', 'patta', 'boruwak', 'kauruth', 'ahu', 'wenna', 'kadila', 'thibb', 'henama', 'chater', 'kala', 'seal', 'rahak', 'wedakma', 'fake', 'origin', 'k', 'ekata.', 'jarawak', 'return', 'karan', 'kohomada', 'mama', 'oni', 'poddak', 'hoda', 'ewala', 'awilla', 'thiyenn', 'item', 'wadak', 'aye', 'karanneth', 'salli', 'aparad', 'padui', 'bag', 'kisima', 'nathi', 'wala', 'thiyena', 'nemei', 'kenek', 'jarawa', 'kale', 'watinn', 'mata', 'hambun', 'witharai', 'press', 'kara', 'karannat', 'ba', 'wagema', 'boka', 'krnne', 'meken', 'sadd', 'adui', 'redda', 'betteri', 'tiyenn', 'charg', 'yanawa', 'wenn', 'button', 'cabl', 'bass', 'ikmanta', 'wenwa', 'connect', 'signal', 'devic', 'tynn', 'packag', 'penn', 'walata', 'nm', 'kiyala', 'mekanan', 'vadak', 'magula', 'melorahak', 'epa\"', '\"meka', 'baya', 'nethuwa', 'eww', 'gnn', 'wdk', 'ne,', 'wda', 'awl', 'e', 'meka.', 'ewaa', 'pack', 'anthimay', 'wadakata', 'mona', 'epaa', 'eddi', 'mek', 'ane', 'naha', 'wedk', 'ek', 'neme', 'denn', 'bala', 'hadala', 'wadi', 'denna', 'awul', 'ekakwath', 'ne.', 'rawattanna', 'gane', 'karana', 'na,', 'ekta', 'meeta', 'athata', 'labunama', 'thiyenne.', 'na.', 'ekt', 'kalayak', 'gann', 'modayo', 'penuma', 'case', 'apoo', 'ekk', 'thawa', 'kisi', 'anthimai', 'enne.', 'nati', 'mun', 'horu', 'scam', 'mu', 'minissunwa', 'inna', 'gnna', 'nethi', 'wima', 'epa.', 'apooo', 'nah', 'dewal', 'wge', 'function', 'unama', 'labila', 'poto', 'sidu', 'ptta', 'bdu', 'math', 'gaththa.', 'meknm', 'vena', 'baduwa', 'nishpadana', 'wedi', 'nam.', 'mala', 'bad', 'danna', 'nisa', 'kiyann', 'karayek', 'mugen', 'hdai', 'appo', 'ekath', 'newey', 'aiyoo', 'wadakma', 'watin', 'awla', 'hariyan', 'gewana', 'gaththa', 'koheda', 'monada', 'kiyapu', 'mn', 'deliv', 'giya.', 'kiyana', 'eewa', 'mehema', 'aragena', 'loku', 'vidiyatama', 'meeka', 'mage', 'qualitiyak', 'result', 'attatama', 'highli', 'enna', 'kal', 'ok', 'nathuwa', 'wasi', 'thamai', 'anith', 'cupiri', 'thibba', 'aulak', 'hetiyata', 'band', 'tiyanwa', 'hituwata', 'aul', 'kma', 'mudalata', 'sadaranai', 'kiyanna', 'clear', 'niyamai', 'pattama', 'widiyatama', 'supirima', 'niyama', 'ganatath', 'hodha', 'ekak.', 'karala', 'ayata', 'thank', 'daraz', 'great', 'recommend', 'supiriyak', 'puluwn', 'ekama', 'best', 'tibba', 'awlk', 'thiy', 'awlak', 'top', 'ona', 'krnna', 'awulak', 'mekanm', 'attama', 'aththatama', 'krl', 'ganin', 'illapu', 'watch', 'supiri..', 'ganna.', 'hodai,', 'tynwa..', 'good', 'paharak', ',', 'haa', 'wow', 'superb', '??', 'gaanata', 'recommended..', 'kenekta', 'mru', 'nathiwa', 'ela', 'nishpadanayak.', 'deyak', 'thawath', 'ekth', 'nan', 'aurudu', 'hodama', 'gammak', 'watina', 'hodta', 'krla', 'kranna', 'thiyanwa.', 'shape', 'ahaa', 'man', 'thama', 'supiri.', 'hondai.', 'eeka', 'dawasema', 'labuna', 'thibuna.', 'widihatama']\n"
     ]
    }
   ],
   "source": [
    "with open('../static/model/vocabulary.txt', 'r', encoding='utf-8') as f:\n",
    "    tokens = [line.strip() for line in f]\n",
    "print(tokens)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ad551537-fb70-4b4e-b8a6-517a988e6ff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "ps = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3753139d-f1dd-48ed-9ddf-6c260f2bc622",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(text):\n",
    "    data = pd.DataFrame([text], columns=['Review (Singlish)'])\n",
    "    # Convert text to lowercase\n",
    "    data[\"Review (Singlish)\"] = data[\"Review (Singlish)\"].apply(lambda x: \" \".join(x.lower() for x in x.split()))\n",
    "    # Remove URLs\n",
    "    data[\"Review (Singlish)\"] = data['Review (Singlish)'].apply(lambda x: \" \".join(re.sub(r'^https?:\\/\\/.*[\\r\\n]*', '', x, flags=re.MULTILINE) for x in x.split()))\n",
    "    # Remove punctuations\n",
    "    data[\"Review (Singlish)\"] = data[\"Review (Singlish)\"].apply(remove_punctuations)\n",
    "    # Remove numbers\n",
    "    data[\"Review (Singlish)\"] = data['Review (Singlish)'].str.replace(r'\\d+', '', regex=True)  # Use raw string\n",
    "    # Remove stopwords\n",
    "    data[\"Review (Singlish)\"] = data[\"Review (Singlish)\"].apply(lambda x: \" \".join(x for x in x.split() if x not in sw))\n",
    "    # Apply stemming\n",
    "    data[\"Review (Singlish)\"] = data[\"Review (Singlish)\"].apply(lambda x: \" \".join(ps.stem(x) for x in x.split()))\n",
    "    return data[\"Review (Singlish)\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "96e24159-0137-485a-a8f7-243d0a9e3718",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorizer(ds, vocabulary):\n",
    "    vectorized_lst = []\n",
    "    \n",
    "    for sentence in ds:\n",
    "        sentence_lst = np.zeros(len(vocabulary))\n",
    "        \n",
    "        for i in range(len(vocabulary)):\n",
    "            if vocabulary[i] in sentence.split():\n",
    "                sentence_lst[i] = 1\n",
    "                \n",
    "        vectorized_lst.append(sentence_lst)\n",
    "        \n",
    "    vectorized_lst_new = np.asarray(vectorized_lst, dtype=np.float32)\n",
    "    \n",
    "    return vectorized_lst_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9ba5d29b-8b6e-4119-9822-bbdfffef4e59",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prediction(vectorized_text):\n",
    "    prediction = model.predict(vectorized_text)\n",
    "    if prediction == 0:\n",
    "        return 'negative'\n",
    "    else:\n",
    "        return 'positive'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f70e1768-6ad1-485c-ac34-f1d01b35840e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'negative'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "txt = \"mekanam wedak na ganna epa\"\n",
    "preprocessed_txt = preprocessing(txt)\n",
    "vectorized_txt = vectorizer(preprocessed_txt, tokens)\n",
    "prediction = get_prediction(vectorized_txt)\n",
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b3bc9f38-ee3f-429e-88f6-fb29e4073001",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'positive'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "txt = \"light eka color full lassanai\"\n",
    "preprocessed_txt = preprocessing(txt)\n",
    "vectorized_txt = vectorizer(preprocessed_txt, tokens)\n",
    "prediction = get_prediction(vectorized_txt)\n",
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2132a91-dac0-476b-94bd-6a4539606adb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
